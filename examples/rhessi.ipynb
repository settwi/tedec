{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb805b64",
   "metadata": {},
   "source": [
    "# RHESSI flare from temporal decomposition paper\n",
    "Here we analyze the 2011 Jul 30 flare observed by RHESSI from the temporal decomposition paper.\n",
    "\n",
    "We don't perform spectroscopy; we just demonstrate the decomposition technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e39a23",
   "metadata": {},
   "source": [
    "## How to: set up this package\n",
    "Please see the `readme.md` file in the root of this repository.\n",
    "\n",
    "## How to: get data\n",
    "The RHESSI flare is downloaded using SSWIDL routines.\n",
    "An appropriate SSWIDL license and installation is required to parse the level zero RHESSI data into a spectrogram.\n",
    "The following snippet downloads the spectrum file and saves it to a .fits:\n",
    "```idl\n",
    "; see https://sprg.ssl.berkeley.edu/~tohban/wiki/index.php/Creating_a_Spectrum_File_Using_the_HESSI_GUI\n",
    "; guide on how to do this\n",
    "\n",
    "; config me\n",
    "t_int = ['30-Jul-2011T01:50:00.000', '30-Jul-2011 02:20:00.000']\n",
    "; see here for binning information\n",
    "; https://hesperia.gsfc.nasa.gov/ssw/hessi/dbase/spec_resp/energy_binning.txt\n",
    "start_energy = alog10(4)\n",
    "end_energy = alog10(200)\n",
    "num = 20\n",
    "expons = dindgen(num) / (num - 1) * (end_energy - start_energy) + start_energy\n",
    "ebins = 10^expons\n",
    "; add a bin at the end for the background\n",
    "energy_bins = [ebins, [500, 800]]\n",
    "\n",
    "; use at least 4s wide bins to prevent rotation effects\n",
    "time_bin_width = 4\n",
    "\n",
    "\n",
    "name = 'trevor-flare-30-jul-2011-logspace-bkg'\n",
    "specfile = name + '_spec.fits'\n",
    "srmfile = name + '_srm.fits'\n",
    "\n",
    "search_network, /enable\n",
    "\n",
    "spec_obj = hsi_spectrum()\n",
    "spec_obj-> set, obs_time_interval=t_int\n",
    "spec_obj-> set, decimation_correct=1    \n",
    "spec_obj-> set, rear_decimation_correct= 0    \n",
    "spec_obj-> set, pileup_correct=0    \n",
    "spec_obj-> set, /sp_semi_calibrated\n",
    "\n",
    "; \"detectors 3, 4, and 9 have the best energy resolution of all the detectors\" -- from the wiki page\n",
    "; whatever\n",
    "spec_obj-> set, seg_index_mask=[1B, 1B, 1B, 1B, 1B, 1B, 1B, 1B, 1B, $\n",
    "\t\t\t    0B, 0B, 0B, 0B, 0B, 0B, 0B, 0B, 0B] \n",
    "spec_obj-> set, sp_chan_binning=0\n",
    "spec_obj-> set, sp_chan_max=0\n",
    "spec_obj-> set, sp_chan_min=0\n",
    "spec_obj-> set, sp_data_unit='Flux'\n",
    "spec_obj-> set, sp_energy_binning=energy_bins\n",
    "spec_obj-> set, sp_semi_calibrated=0B\n",
    "spec_obj-> set, sp_time_interval=time_bin_width\n",
    "spec_obj-> set, sum_flag=1\n",
    "spec_obj-> set, use_flare_xyoffset=1\n",
    "\n",
    "spec_obj->filewrite, /buildsrm, all_simplify=0, srmfile=srmfile, specfile=specfile\n",
    "print, 'done'\n",
    "```\n",
    "\n",
    "## How to: load data\n",
    "We read the data in using `sunkit-spex` at a specific git commit. It may be installed using `pip`:\n",
    "```bash\n",
    "git clone https://github.com/sunpy/sunkit-spex.git\n",
    "cd sunkit-spex\n",
    "git checkout dbab7763acbc97017374d3cc86f1c84a3dc52d5c\n",
    "# If not using `uv` for Python version management, just use `pip`\n",
    "uv pip install .\n",
    "```\n",
    "\n",
    "We use some plotting functions from `yaff`:\n",
    "```bash\n",
    "git clone https://github.com/settwi/yaff.git\n",
    "cd yaff\n",
    "git checkout v0\n",
    "# If not using `uv` for Python version management, just use `pip`\n",
    "uv pip install .[examples]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e991054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sunkit_spex.extern import rhessi\n",
    "from yaff.plotting import stairs_with_error\n",
    "\n",
    "import astropy.units as u\n",
    "import astropy.time as atime\n",
    "from astropy.visualization import quantity_support\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tedec import decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803440f9",
   "metadata": {},
   "source": [
    "## Load in the data and perform the temporal decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9bddf1",
   "metadata": {},
   "source": [
    "### First, load the data and slice out the time range we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest(a, v):\n",
    "    return np.argmin(np.abs(a - v))\n",
    "\n",
    "\n",
    "spectrum_file = \"trevor-flare-30-jul-2011-logspace-bkg_spec.fits\"\n",
    "srm_file = \"trevor-flare-30-jul-2011-logspace-bkg_srm.fits\"\n",
    "\n",
    "data = rhessi.RhessiLoader(spectrum_fn=spectrum_file, srm_fn=srm_file)\n",
    "\n",
    "start_event_time = atime.Time(\"2011-07-30T02:08:20\")\n",
    "end_event_time = atime.Time(\"2011-07-30T02:10:20\")\n",
    "start_background_time = atime.Time(\"2011-07-30T01:54:00\")\n",
    "end_background_time = atime.Time(\"2011-07-30T01:56:00\")\n",
    "\n",
    "data.update_event_times(start_event_time, end_event_time)\n",
    "data.update_background_times(start_background_time, end_background_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e55a5a",
   "metadata": {},
   "source": [
    "### Slice out the data from sunkit-spex format into a simplified data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f490f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_rhessi_data(rl: rhessi.RhessiLoader) -> dict[str, u.Quantity]:\n",
    "    \"\"\"Take a sunkit_spex object and extract the data we want from it\"\"\"\n",
    "    tbins = atime.Time(\n",
    "        np.concatenate(\n",
    "            (rl._spectrum[\"time_bins\"][:, 0], [rl._spectrum[\"time_bins\"][-1, -1]])\n",
    "        )\n",
    "    )\n",
    "    ebins = np.unique(rl[\"count_channel_bins\"].flatten()) << u.keV\n",
    "\n",
    "    cts = rl._spectrum[\"counts\"] / rl._spectrum[\"livetime\"]\n",
    "    err = rl._spectrum[\"counts_err\"] / rl._spectrum[\"livetime\"]\n",
    "\n",
    "    tai, tbi = (\n",
    "        nearest(tbins, atime.Time(rl._start_event_time)),\n",
    "        nearest(tbins, atime.Time(rl._end_event_time)),\n",
    "    )\n",
    "    cut_cts = cts[tai:tbi] << u.ct\n",
    "    cut_err = err[tai:tbi] << u.ct\n",
    "    cut_tbins = tbins[tai : tbi + 1]\n",
    "\n",
    "    return {\n",
    "        \"time_bins\": cut_tbins,\n",
    "        \"energy_bins\": ebins,\n",
    "        \"cts\": cut_cts.T,\n",
    "        \"cts_err\": cut_err.T,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5fbb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced = prep_rhessi_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630f230",
   "metadata": {},
   "source": [
    "### Then, perform the decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to apply any sort of lightcurve summations by indexing the\n",
    "# energy midpoints, as they have the same shape as the counts.\n",
    "energy_mids = sliced[\"energy_bins\"][:-1] + np.diff(sliced[\"energy_bins\"]) / 2\n",
    "\n",
    "# Template energies for (thermal, nonthermal, background).\n",
    "TH_ENG = 5.5 << u.keV\n",
    "NTH_ENG = 81 << u.keV\n",
    "BKG_ENG = 320 << u.keV\n",
    "\n",
    "# Find the indices of the count bins that are closest to our desired energies\n",
    "th_idx = nearest(TH_ENG, energy_mids)\n",
    "nth_idx = nearest(NTH_ENG, energy_mids)\n",
    "bkg_idx = nearest(BKG_ENG, energy_mids)\n",
    "\n",
    "# Package up all of our data into a DataPacket\n",
    "pack = decomp.DataPacket(\n",
    "    data=sliced[\"cts\"],\n",
    "    basis_timeseries=[\n",
    "        # Take a few thermal and nonthermal and bkg energy bands and sum them\n",
    "        # together to make the basis timeseries.\n",
    "        # This helps with statistics and also makes it so that\n",
    "        # no single energy band dominates the behavior of the emission\n",
    "        sliced[\"cts\"][th_idx - 1 : th_idx + 2].sum(axis=0),\n",
    "        sliced[\"cts\"][nth_idx - 1 : nth_idx + 2].sum(axis=0),\n",
    "        sliced[\"cts\"][bkg_idx - 1 : bkg_idx + 2].sum(axis=0),\n",
    "    ],\n",
    "    # In this case, because we are using a background light curve,\n",
    "    # we want no constant offset.\n",
    "    constant_offset=False,\n",
    ")\n",
    "\n",
    "# Decompose the data using the `decomp` module\n",
    "# See the docstring for more info\n",
    "decomposed = decomp.bootstrap(\n",
    "    dp=pack, errors=sliced[\"cts_err\"], num_iter=3000, clip_negative=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deca44f",
   "metadata": {},
   "source": [
    "## Plot the decomposed data on top of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per the docstring, the decomposed data are the first N-1 entries, while the\n",
    "# intercept is included in the final entry.\n",
    "index_map = {\"thermal\": 0, \"nonthermal\": 1, \"background\": 2}\n",
    "\n",
    "# Energy binning is nonuniform, so we divide it out\n",
    "# for a nicer looking spectrum\n",
    "de = np.diff(sliced[\"energy_bins\"]) << u.keV\n",
    "\n",
    "# Average the live time across all detector pairs\n",
    "dt = np.sum(np.diff(sliced[\"time_bins\"])).to(u.s)\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "all_counts = sliced[\"cts\"].sum(axis=1)\n",
    "all_errors = np.sqrt(np.sum(sliced[\"cts_err\"] ** 2, axis=1))\n",
    "\n",
    "with quantity_support():\n",
    "    stairs_with_error(\n",
    "        sliced[\"energy_bins\"],\n",
    "        all_counts / de / dt,\n",
    "        all_errors / de / dt,\n",
    "        ax=ax,\n",
    "        label=\"data\",\n",
    "        line_kw={\"color\": \"black\"},\n",
    "    )\n",
    "    for label, index in index_map.items():\n",
    "        # Get the samples associated with your pseudobasis\n",
    "        samples = decomposed[:, index, :]\n",
    "        avg_cts = np.mean(samples, axis=0) << u.ct\n",
    "        avg_std = np.std(samples, axis=0) << u.ct\n",
    "\n",
    "        stairs_with_error(\n",
    "            sliced[\"energy_bins\"],\n",
    "            avg_cts / de / dt,\n",
    "            avg_std / de / dt,\n",
    "            ax=ax,\n",
    "            label=label,\n",
    "        )\n",
    "\n",
    "ax.legend()\n",
    "ax.set(\n",
    "    title=\"RHESSI decomposition\",\n",
    "    xscale=\"log\",\n",
    "    yscale=\"log\",\n",
    "    xlim=(4, 100),\n",
    "    ylim=(0.01, 2e3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cd680b",
   "metadata": {},
   "source": [
    "### We can see that the decomposed data captures the various components well.\n",
    "### This is equivalent to Figure 4 from the paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
