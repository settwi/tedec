{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb805b64",
   "metadata": {},
   "source": [
    "# STIX flare from temporal decomposition paper\n",
    "Here we analyze the 2022 Apr 20 flare observed by SoLO/STIX from the temporal decomposition paper.\n",
    "\n",
    "We don't perform spectroscopy; we just demonstrate the decomposition technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e39a23",
   "metadata": {},
   "source": [
    "## How to: set up this package\n",
    "Please see the `readme.md` file in the root of this repository.\n",
    "\n",
    "## How to: get data\n",
    "Each STIX flare has its own unique ID. In this case, the data ID is `2204205961`.\n",
    "You may download the data via the shell:\n",
    "```bash\n",
    "id=2204205961\n",
    "stix_website='https://datacenter.stix.i4ds.net/download/fits/bsd'\n",
    "curl \"$stix_website/$id\" > \"$id.fits\"\n",
    "```\n",
    "\n",
    "## How to: load data\n",
    "We read the data in using `yaff` version `v0`. It may be installed via `pip`:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/settwi/yaff.git\n",
    "cd yaff\n",
    "git checkout v0\n",
    "# If not using `uv` for Python version management, just use `pip`\n",
    "uv pip install .[examples]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e991054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaff.extern import stix\n",
    "from yaff.plotting import stairs_with_error\n",
    "\n",
    "import astropy.units as u\n",
    "import astropy.time as atime\n",
    "from astropy.visualization import quantity_support\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tedec import decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e81be",
   "metadata": {},
   "source": [
    "## Define some helper functions for slicing up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77713793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest(a: np.ndarray, v):\n",
    "    \"\"\"Get the index of the element in `a` whose value is closest to `v`\"\"\"\n",
    "    return np.argmin(np.abs(a - v))\n",
    "\n",
    "\n",
    "def slice_spectrogram(spectrogram: dict, ta: atime.Time, tb: atime.Time) -> dict:\n",
    "    \"\"\"Take in a spectrogram dictionary and slice it up given two times.\"\"\"\n",
    "    # Change STIX UTC to Earth arrival time UTC\n",
    "    time_bins = spectrogram[\"time_bin_edges\"] + spectrogram[\"earth_spacecraft_dt\"]\n",
    "\n",
    "    # Find the time bin indices which are closest to our selected times\n",
    "    ia, ib = nearest(time_bins, ta), nearest(time_bins, tb)\n",
    "\n",
    "    ebins = spectrogram[\"energy_bin_edges\"].copy()\n",
    "    # The last energy bin is `nan`, so make it really large\n",
    "    ebins[np.isnan(ebins)] = 1 << u.MeV\n",
    "\n",
    "    # Slice out the data and time bins we want;\n",
    "    # we need the \"-1\" because there are N time bins,\n",
    "    # but N+1 time bin edges\n",
    "    cts = spectrogram[\"counts\"].T[:, ia : ib - 1]\n",
    "    cts_err = spectrogram[\"counts_error\"].T[:, ia : ib - 1]\n",
    "    cut_livetime = spectrogram[\"livetime\"][ia : ib - 1]\n",
    "    cut_time_bins = time_bins[ia:ib]\n",
    "\n",
    "    return {\n",
    "        \"time_bins\": cut_time_bins,\n",
    "        \"cts\": cts,\n",
    "        \"cts_err\": cts_err,\n",
    "        \"livetime\": cut_livetime,\n",
    "        \"energy_bins\": ebins,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803440f9",
   "metadata": {},
   "source": [
    "## Load in the data and perform the temporal decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9bddf1",
   "metadata": {},
   "source": [
    "### First, load the data and slice out the time range we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"2204205961.fits\"\n",
    "full_spectrogram = stix.load_pixel_data_to_spectrogram(file_name)\n",
    "\n",
    "# The analysis interval we used in the paper\n",
    "TA = atime.Time(\"2022-04-20T01:12:20\")\n",
    "TB = atime.Time(\"2022-04-20T01:13:00\")\n",
    "sliced = slice_spectrogram(full_spectrogram, TA, TB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630f230",
   "metadata": {},
   "source": [
    "### Then, perform the decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to apply any sort of lightcurve summations by indexing the\n",
    "# energy midpoints, as they have the same shape as the counts.\n",
    "energy_mids = sliced[\"energy_bins\"][:-1] + np.diff(sliced[\"energy_bins\"]) / 2\n",
    "\n",
    "# Template energies for (thermal, nonthermal, background).\n",
    "# Alternatively, a constant offset may be used for STIX\n",
    "# because the background is basically flat across time.\n",
    "TH_ENG = 6 << u.keV\n",
    "NTH_ENG = 19 << u.keV\n",
    "BKG_ENG = 80 << u.keV\n",
    "\n",
    "# Find the indices of the count bins that are closest to our desired energies\n",
    "th_idx = nearest(TH_ENG, energy_mids)\n",
    "nth_idx = nearest(NTH_ENG, energy_mids)\n",
    "bkg_idx = nearest(BKG_ENG, energy_mids)\n",
    "\n",
    "# Package up all of our data into a DataPacket\n",
    "pack = decomp.DataPacket(\n",
    "    data=sliced[\"cts\"],\n",
    "    basis_timeseries=[\n",
    "        # Take a few thermal and nonthermal and bkg energy bands and sum them\n",
    "        # together to make the basis timeseries.\n",
    "        # This helps with statistics and also makes it so that\n",
    "        # no single energy band dominates the behavior of the emission\n",
    "        sliced[\"cts\"][th_idx - 1 : th_idx + 2].sum(axis=0),\n",
    "        sliced[\"cts\"][nth_idx - 1 : nth_idx + 2].sum(axis=0),\n",
    "        sliced[\"cts\"][bkg_idx - 1 : bkg_idx + 2].sum(axis=0),\n",
    "    ],\n",
    "    # In this case, because we are using a background light curve,\n",
    "    # we want no constant offset.\n",
    "    constant_offset=False,\n",
    ")\n",
    "\n",
    "# Decompose the data using the `decomp` module\n",
    "# See the docstring for more info\n",
    "decomposed = decomp.bootstrap(\n",
    "    dp=pack, errors=sliced[\"cts_err\"], num_iter=3000, clip_negative=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deca44f",
   "metadata": {},
   "source": [
    "## Plot the decomposed data on top of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per the docstring, the decomposed data are the first N-1 entries, while the\n",
    "# intercept is included in the final entry.\n",
    "index_map = {\"thermal\": 0, \"nonthermal\": 1, \"background\": 2}\n",
    "\n",
    "# Energy binning is nonuniform, so we divide it out\n",
    "# for a nicer looking spectrum\n",
    "de = np.diff(sliced[\"energy_bins\"]) << u.keV\n",
    "\n",
    "# Average the live time across all detector pairs\n",
    "avg_livetime = sliced[\"livetime\"].mean(axis=1)\n",
    "dt = np.sum(np.diff(sliced[\"time_bins\"]) * avg_livetime).to(u.s)\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "all_counts = sliced[\"cts\"].sum(axis=1)\n",
    "all_errors = np.sqrt(np.sum(sliced[\"cts_err\"] ** 2, axis=1))\n",
    "\n",
    "with quantity_support():\n",
    "    stairs_with_error(\n",
    "        sliced[\"energy_bins\"],\n",
    "        all_counts / de / dt,\n",
    "        all_errors / de / dt,\n",
    "        ax=ax,\n",
    "        label=\"data\",\n",
    "        line_kw={\"color\": \"black\"},\n",
    "    )\n",
    "    for label, index in index_map.items():\n",
    "        # Get the samples associated with your pseudobasis\n",
    "        samples = decomposed[:, index, :]\n",
    "        avg_cts = np.mean(samples, axis=0) << u.ct\n",
    "        avg_std = np.std(samples, axis=0) << u.ct\n",
    "\n",
    "        stairs_with_error(\n",
    "            sliced[\"energy_bins\"],\n",
    "            avg_cts / de / dt,\n",
    "            avg_std / de / dt,\n",
    "            ax=ax,\n",
    "            label=label,\n",
    "        )\n",
    "\n",
    "ax.legend()\n",
    "ax.set(\n",
    "    title=\"STIX decomposition\",\n",
    "    xscale=\"log\",\n",
    "    yscale=\"log\",\n",
    "    xlim=(4, 100),\n",
    "    ylim=(0.1, 4e4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cd680b",
   "metadata": {},
   "source": [
    "### We can see that the decomposed data captures the various components well.\n",
    "### This is equivalent to Figure 2 from the paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
